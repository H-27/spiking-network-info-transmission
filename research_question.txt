Primary research question
- When do horizontal (within-layer) connections improve vs impair information transmission across layers?

Testable hypotheses
- H1: With weak, localized input, moderate horizontal recurrence boosts transmission (higher downstream decoding/MI, lower error).
- H2: With strong input, too much recurrence increases synchrony, reduces sparsity, and degrades transmission (lower decoding/MI).
- H3: Clustered horizontal connectivity preserves “cluster identity” across layers better than random recurrence (higher class separability downstream).
- H4: Recurrence increases temporal integration (slower but more robust propagation) vs purely feedforward (faster but brittle).

Independent variables (manipulations)
- Recurrence present vs absent.
- Horizontal strength/density: sweep weight scale and density.
- Horizontal structure: clustered vs random.
- Input regime: strong vs weak; clustered vs diffuse; steady vs pulsed; add input noise.
- Optional: plasticity off vs on (Hebbian/STDP), traces enabled.

Key metrics (per layer)
- Transmission gain: mean spike count ratio (layer k / input).
- Decoding accuracy: train a simple linear/logistic readout to classify input cluster; report accuracy per layer.
- Mutual information: MI(input label; binned population activity) via discretization or kNN MI.
- Temporal fidelity: correlation between input PSTH and downstream PSTH; peak latency shift.
- Synchrony: mean pairwise spike-count correlation; Fano factor; population synchrony index.
- Sparsity: Treves–Rolls or Gini.
- Dimensionality: PCA participation ratio; variance explained.
- Stability: ISI CV; oscillatory power (FFT of population rate).

Experimental design (minimal grid)
- 2–3 layers; feedforward fixed.
- Conditions:
  - Recurrence off (baseline).
  - Recurrence on: strengths ∈ {0.2, 0.5, 1.0}, densities ∈ {0.1, 0.3}, clustered vs random.
- Stimuli:
  - Weak vs strong input rates.
  - Localized cluster vs diffuse activation.
- Trials: ≥20 seeds per condition; 400 ms per trial; 5–10 ms binning.

Analysis plan
- Compute all metrics per trial and layer; average with CI across seeds.
- Primary outcomes: downstream decoding accuracy and MI vs recurrence strength/density.
- Secondary: synchrony and sparsity vs recurrence; latency and gain vs input strength.
- Compare clustered vs random recurrence at matched in-degree (control for total input).

Recommended plots
- Accuracy/MI vs recurrence strength (lines for each density/structure).
- Synchrony and sparsity vs strength.
- PSTH and latency across layers (weak vs strong input).
- Rasters and voltage snapshots for representative runs.
- Connectivity heatmaps (feedforward + lateral) used in each condition.

Controls
- Degree-matched shuffled recurrence (null model).
- Weight-norm-matched comparisons (keep total incoming fixed).
- Plasticity off vs on (if on, measure pre/post metrics).

This gives you focused, testable questions, a small parameter sweep, and concrete metrics to decide when recurrence helps or hurts transmission.
